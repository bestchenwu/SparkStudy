2019-01-01 13:02:05 WARN  Utils:66 - Your hostname, sweet resolves to a loopback address: 127.0.0.1; using 192.168.0.112 instead (on interface wlan0)
2019-01-01 13:02:05 WARN  Utils:66 - Set SPARK_LOCAL_IP if you need to bind to another address
2019-01-01 13:02:06 WARN  NativeCodeLoader:62 - Unable to load native-hadoop library for your platform... using builtin-java classes where applicable
2019-01-01 13:02:06 INFO  SparkContext:54 - Running Spark version 2.3.0
2019-01-01 13:02:06 INFO  SparkContext:54 - Submitted application: CountLogTask
2019-01-01 13:02:06 INFO  SecurityManager:54 - Changing view acls to: sweet
2019-01-01 13:02:06 INFO  SecurityManager:54 - Changing modify acls to: sweet
2019-01-01 13:02:06 INFO  SecurityManager:54 - Changing view acls groups to: 
2019-01-01 13:02:06 INFO  SecurityManager:54 - Changing modify acls groups to: 
2019-01-01 13:02:06 INFO  SecurityManager:54 - SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(sweet); groups with view permissions: Set(); users  with modify permissions: Set(sweet); groups with modify permissions: Set()
2019-01-01 13:02:06 INFO  Utils:54 - Successfully started service 'sparkDriver' on port 35797.
2019-01-01 13:02:07 INFO  SparkEnv:54 - Registering MapOutputTracker
2019-01-01 13:02:07 INFO  SparkEnv:54 - Registering BlockManagerMaster
2019-01-01 13:02:07 INFO  BlockManagerMasterEndpoint:54 - Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information
2019-01-01 13:02:07 INFO  BlockManagerMasterEndpoint:54 - BlockManagerMasterEndpoint up
2019-01-01 13:02:07 INFO  DiskBlockManager:54 - Created local directory at /tmp/blockmgr-31cc8e6c-62ba-49db-b565-60f0a47932b1
2019-01-01 13:02:07 INFO  MemoryStore:54 - MemoryStore started with capacity 366.3 MB
2019-01-01 13:02:07 INFO  SparkEnv:54 - Registering OutputCommitCoordinator
2019-01-01 13:02:07 INFO  log:192 - Logging initialized @2437ms
2019-01-01 13:02:07 INFO  Server:346 - jetty-9.3.z-SNAPSHOT
2019-01-01 13:02:07 INFO  Server:414 - Started @2572ms
2019-01-01 13:02:07 INFO  AbstractConnector:278 - Started ServerConnector@46fa346d{HTTP/1.1,[http/1.1]}{0.0.0.0:4052}
2019-01-01 13:02:07 INFO  Utils:54 - Successfully started service 'SparkUI' on port 4052.
2019-01-01 13:02:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@cc62a3b{/jobs,null,AVAILABLE,@Spark}
2019-01-01 13:02:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@39c11e6c{/jobs/json,null,AVAILABLE,@Spark}
2019-01-01 13:02:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@324dcd31{/jobs/job,null,AVAILABLE,@Spark}
2019-01-01 13:02:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@72bca894{/jobs/job/json,null,AVAILABLE,@Spark}
2019-01-01 13:02:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@433ffad1{/stages,null,AVAILABLE,@Spark}
2019-01-01 13:02:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1fc793c2{/stages/json,null,AVAILABLE,@Spark}
2019-01-01 13:02:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2575f671{/stages/stage,null,AVAILABLE,@Spark}
2019-01-01 13:02:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2d35442b{/stages/stage/json,null,AVAILABLE,@Spark}
2019-01-01 13:02:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@27f9e982{/stages/pool,null,AVAILABLE,@Spark}
2019-01-01 13:02:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@4593ff34{/stages/pool/json,null,AVAILABLE,@Spark}
2019-01-01 13:02:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@37d3d232{/storage,null,AVAILABLE,@Spark}
2019-01-01 13:02:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@30c0ccff{/storage/json,null,AVAILABLE,@Spark}
2019-01-01 13:02:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@581d969c{/storage/rdd,null,AVAILABLE,@Spark}
2019-01-01 13:02:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@22db8f4{/storage/rdd/json,null,AVAILABLE,@Spark}
2019-01-01 13:02:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2b46a8c1{/environment,null,AVAILABLE,@Spark}
2019-01-01 13:02:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1d572e62{/environment/json,null,AVAILABLE,@Spark}
2019-01-01 13:02:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@29caf222{/executors,null,AVAILABLE,@Spark}
2019-01-01 13:02:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@46cf05f7{/executors/json,null,AVAILABLE,@Spark}
2019-01-01 13:02:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5851bd4f{/executors/threadDump,null,AVAILABLE,@Spark}
2019-01-01 13:02:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@7cd1ac19{/executors/threadDump/json,null,AVAILABLE,@Spark}
2019-01-01 13:02:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2f40a43{/static,null,AVAILABLE,@Spark}
2019-01-01 13:02:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@5949eba8{/,null,AVAILABLE,@Spark}
2019-01-01 13:02:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@6e0ff644{/api,null,AVAILABLE,@Spark}
2019-01-01 13:02:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@2d0566ba{/jobs/job/kill,null,AVAILABLE,@Spark}
2019-01-01 13:02:07 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@733037{/stages/stage/kill,null,AVAILABLE,@Spark}
2019-01-01 13:02:07 INFO  SparkUI:54 - Bound SparkUI to 0.0.0.0, and started at http://sweet.local:4052
2019-01-01 13:02:07 INFO  SparkContext:54 - Added JAR file:/data/StudySpace/SparkStudy/target/spark-1.0-SNAPSHOT-jar-with-dependencies.jar at spark://sweet.local:35797/jars/spark-1.0-SNAPSHOT-jar-with-dependencies.jar with timestamp 1546318927552
2019-01-01 13:02:07 INFO  StandaloneAppClient$ClientEndpoint:54 - Connecting to master spark://localhost:7077...
2019-01-01 13:02:07 INFO  TransportClientFactory:267 - Successfully created connection to localhost/127.0.0.1:7077 after 43 ms (0 ms spent in bootstraps)
2019-01-01 13:02:07 INFO  StandaloneSchedulerBackend:54 - Connected to Spark cluster with app ID app-20190101130207-0001
2019-01-01 13:02:07 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor added: app-20190101130207-0001/0 on worker-20190101123742-192.168.0.112-35197 (192.168.0.112:35197) with 2 core(s)
2019-01-01 13:02:07 INFO  StandaloneSchedulerBackend:54 - Granted executor ID app-20190101130207-0001/0 on hostPort 192.168.0.112:35197 with 2 core(s), 1024.0 MB RAM
2019-01-01 13:02:07 INFO  Utils:54 - Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 36931.
2019-01-01 13:02:07 INFO  NettyBlockTransferService:54 - Server created on sweet.local:36931
2019-01-01 13:02:07 INFO  BlockManager:54 - Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy
2019-01-01 13:02:07 INFO  BlockManagerMaster:54 - Registering BlockManager BlockManagerId(driver, sweet.local, 36931, None)
2019-01-01 13:02:07 INFO  BlockManagerMasterEndpoint:54 - Registering block manager sweet.local:36931 with 366.3 MB RAM, BlockManagerId(driver, sweet.local, 36931, None)
2019-01-01 13:02:07 INFO  StandaloneAppClient$ClientEndpoint:54 - Executor updated: app-20190101130207-0001/0 is now RUNNING
2019-01-01 13:02:07 INFO  BlockManagerMaster:54 - Registered BlockManager BlockManagerId(driver, sweet.local, 36931, None)
2019-01-01 13:02:07 INFO  BlockManager:54 - Initialized BlockManager: BlockManagerId(driver, sweet.local, 36931, None)
2019-01-01 13:02:08 INFO  ContextHandler:781 - Started o.s.j.s.ServletContextHandler@1517f633{/metrics/json,null,AVAILABLE,@Spark}
2019-01-01 13:02:08 INFO  StandaloneSchedulerBackend:54 - SchedulerBackend is ready for scheduling beginning after reached minRegisteredResourcesRatio: 0.0
2019-01-01 13:02:09 INFO  MemoryStore:54 - Block broadcast_0 stored as values in memory (estimated size 240.1 KB, free 366.1 MB)
2019-01-01 13:02:10 INFO  MemoryStore:54 - Block broadcast_0_piece0 stored as bytes in memory (estimated size 23.1 KB, free 366.0 MB)
2019-01-01 13:02:10 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on sweet.local:36931 (size: 23.1 KB, free: 366.3 MB)
2019-01-01 13:02:10 INFO  SparkContext:54 - Created broadcast 0 from textFile at CountLogTask.scala:15
2019-01-01 13:02:11 INFO  FileInputFormat:249 - Total input paths to process : 1
2019-01-01 13:02:11 INFO  SparkContext:54 - Starting job: count at CountLogTask.scala:24
2019-01-01 13:02:11 INFO  DAGScheduler:54 - Got job 0 (count at CountLogTask.scala:24) with 2 output partitions
2019-01-01 13:02:11 INFO  DAGScheduler:54 - Final stage: ResultStage 0 (count at CountLogTask.scala:24)
2019-01-01 13:02:11 INFO  DAGScheduler:54 - Parents of final stage: List()
2019-01-01 13:02:11 INFO  DAGScheduler:54 - Missing parents: List()
2019-01-01 13:02:11 INFO  DAGScheduler:54 - Submitting ResultStage 0 (MapPartitionsRDD[2] at filter at CountLogTask.scala:16), which has no missing parents
2019-01-01 13:02:11 INFO  MemoryStore:54 - Block broadcast_1 stored as values in memory (estimated size 3.3 KB, free 366.0 MB)
2019-01-01 13:02:11 INFO  MemoryStore:54 - Block broadcast_1_piece0 stored as bytes in memory (estimated size 2022.0 B, free 366.0 MB)
2019-01-01 13:02:11 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on sweet.local:36931 (size: 2022.0 B, free: 366.3 MB)
2019-01-01 13:02:11 INFO  SparkContext:54 - Created broadcast 1 from broadcast at DAGScheduler.scala:1039
2019-01-01 13:02:11 INFO  DAGScheduler:54 - Submitting 2 missing tasks from ResultStage 0 (MapPartitionsRDD[2] at filter at CountLogTask.scala:16) (first 15 tasks are for partitions Vector(0, 1))
2019-01-01 13:02:11 INFO  TaskSchedulerImpl:54 - Adding task set 0.0 with 2 tasks
2019-01-01 13:02:12 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Registered executor NettyRpcEndpointRef(spark-client://Executor) (192.168.0.112:48918) with ID 0
2019-01-01 13:02:12 INFO  TaskSetManager:54 - Starting task 0.0 in stage 0.0 (TID 0, 192.168.0.112, executor 0, partition 0, PROCESS_LOCAL, 7907 bytes)
2019-01-01 13:02:12 INFO  TaskSetManager:54 - Starting task 1.0 in stage 0.0 (TID 1, 192.168.0.112, executor 0, partition 1, PROCESS_LOCAL, 7907 bytes)
2019-01-01 13:02:12 INFO  BlockManagerMasterEndpoint:54 - Registering block manager 192.168.0.112:56431 with 366.3 MB RAM, BlockManagerId(0, 192.168.0.112, 56431, None)
2019-01-01 13:02:14 INFO  BlockManagerInfo:54 - Added broadcast_1_piece0 in memory on 192.168.0.112:56431 (size: 2022.0 B, free: 366.3 MB)
2019-01-01 13:02:14 INFO  BlockManagerInfo:54 - Added broadcast_0_piece0 in memory on 192.168.0.112:56431 (size: 23.1 KB, free: 366.3 MB)
2019-01-01 13:02:15 INFO  TaskSetManager:54 - Finished task 1.0 in stage 0.0 (TID 1) in 3683 ms on 192.168.0.112 (executor 0) (1/2)
2019-01-01 13:02:15 INFO  TaskSetManager:54 - Finished task 0.0 in stage 0.0 (TID 0) in 3881 ms on 192.168.0.112 (executor 0) (2/2)
2019-01-01 13:02:15 INFO  TaskSchedulerImpl:54 - Removed TaskSet 0.0, whose tasks have all completed, from pool 
2019-01-01 13:02:15 INFO  DAGScheduler:54 - ResultStage 0 (count at CountLogTask.scala:24) finished in 4.549 s
2019-01-01 13:02:15 INFO  DAGScheduler:54 - Job 0 finished: count at CountLogTask.scala:24, took 4.653138 s
count=1512019-01-01 13:02:15 INFO  AbstractConnector:318 - Stopped Spark@46fa346d{HTTP/1.1,[http/1.1]}{0.0.0.0:4052}
2019-01-01 13:02:15 INFO  SparkUI:54 - Stopped Spark web UI at http://sweet.local:4052
2019-01-01 13:02:15 INFO  StandaloneSchedulerBackend:54 - Shutting down all executors
2019-01-01 13:02:15 INFO  CoarseGrainedSchedulerBackend$DriverEndpoint:54 - Asking each executor to shut down
2019-01-01 13:02:15 INFO  MapOutputTrackerMasterEndpoint:54 - MapOutputTrackerMasterEndpoint stopped!
2019-01-01 13:02:16 INFO  MemoryStore:54 - MemoryStore cleared
2019-01-01 13:02:16 INFO  BlockManager:54 - BlockManager stopped
2019-01-01 13:02:16 INFO  BlockManagerMaster:54 - BlockManagerMaster stopped
2019-01-01 13:02:16 INFO  OutputCommitCoordinator$OutputCommitCoordinatorEndpoint:54 - OutputCommitCoordinator stopped!
2019-01-01 13:02:16 INFO  SparkContext:54 - Successfully stopped SparkContext
2019-01-01 13:02:16 INFO  ShutdownHookManager:54 - Shutdown hook called
2019-01-01 13:02:16 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-004097c2-fe15-44ce-8a92-69122668100d
2019-01-01 13:02:16 INFO  ShutdownHookManager:54 - Deleting directory /tmp/spark-e16217c1-70fa-4e5d-803c-2da0f8fd34a0
